---
title: "Unsupervised Learning of Depth and Ego-Motion from Cylindrical Panoramic Video"
collection: publications
permalink: /publication/2019/12/aivr
excerpt: 'We introduce a convolutional neural network model for unsupervised learning of depth and ego-motion from cylindrical panoramic video.'
date: 2019-12-11
venue: 'IEEE Int. Conf. Artificial Intelligence and Virtual Reality (AIVR)'
paperurl: 'https://arxiv.org/abs/1901.00979'
citation: 'A. Sharma and J. Ventura, &quot;Unsupervised Learning of Depth and Ego-Motion from Cylindrical Panoramic Video,&quot; in <i>IEEE Int. Conf. Artificial Intelligence and Virtual Reality (AIVR)</i>, San Diego, 2019.'

---

We introduce a convolutional neural network model for  unsupervised  learning  of  depth  and  ego-motion  from  cylindrical  panoramic  video.  Panoramic  depth  estimation  is  an  important  technology  for  applications  such  as  virtual  reality,  3D modeling, and autonomous robotic navigation. In contrast to previous  approaches  for  applying  convolutional  neural  networks  to panoramic imagery, we use the cylindrical panoramic projection which  allows  for  the  use  of  the  traditional  CNN  layers  such  as convolutional filters and max pooling without modification. Our evaluation  of  synthetic  and  real  data  shows  that  unsupervised learning  of  depth  and  ego-motion  on  cylindrical  panoramic  images can produce high-quality depth maps and that an increased field-of-view  improves  ego-motion  estimation  accuracy.  We  alsointroduce Headcam, a novel dataset of panoramic video collected from a helmet-mounted camera while biking in an urban setting.

[Download paper here](https://arxiv.org/abs/1901.00979)

### Bibtex

```bibtex
@inproceedings{sharma2019unsupervised,
  title={Unsupervised Learning of Depth and Ego-Motion from Cylindrical Panoramic Video},
  author={Sharma, Alisha and Ventura, Jonathan},
  booktitle={IEEE Int. Conf. Artificial Intelligence and Virtual Reality (AIVR)},
  year={2019}
}
```
